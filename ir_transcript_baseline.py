# -*- coding: utf-8 -*-
"""IR_transcript_baseline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zYGP24TUqnHvcnvyFEAo5vbsu2Co8nFt
"""

!pip install transformers faiss-cpu opencv-python torch torchvision
!pip install datasets
!pip install yt-dlp
!pip install webvtt-py
!pip install evaluate
!pip install rouge_score
!pip install accelerate bitsandbytes

from google.colab import drive
drive.mount('/content/drive')

from datasets import load_dataset

dataset = load_dataset("lmms-lab/Video-MME")

print(dataset['test'])

dataset.num_rows['test']

dataset['test'][:5]

dataset["test"][5]

import webvtt

def vtt_to_text(vtt_file):
    lines = []
    for caption in webvtt.read(vtt_file):
        lines.append(caption.text)
    return " ".join(lines)

import os
import cv2
import urllib.request
from yt_dlp import YoutubeDL
import json

transcripts = {}
transcript_path = "/content/drive/MyDrive/COMPSCI646-F25/project/transcripts.json"

def download_youtube(url, vid_id=None, cookie_file="youtube.com_cookies.txt"):
    """
    Downloads a YouTube video transcript using yt-dlp with optional cookie authentication.
    """

    output_template = os.path.join("videos/",f"{vid_id or '%(id)s'}.%(ext)s")

    ydl_opts = {
      'skip_download': True,
      'writesubtitles': True,
      'writeautomaticsub': True,
      'subtitleslangs': ['en'],
      'outtmpl': output_template,
      }

    if os.path.exists(cookie_file):
      ydl_opts['cookiefile'] = cookie_file

    try:
      with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)
        vtt_file = f"videos/{vid_id}.en.vtt"
        transcripts[vid_id] = vtt_to_text(vtt_file)
      with open(transcript_path, "w") as f:
                json.dump(transcripts, f)
    except Exception as e:
        print(f"Failed to download {vid_id or url}: {e}")
        return None

video_paths = {}
for i in range(150):
    row = dataset['test'][i]
    vid_id = row['video_id']
    url = row['url']
    print(url)
    path = download_youtube(url, vid_id=vid_id)
    video_paths[vid_id] = path

print("Downloaded videos:", list(video_paths.items()))

# Read from the JSON file if already transcripts downloaded
with open(transcript_path, "r") as f:
    transcripts = json.load(f)

from sentence_transformers import SentenceTransformer
import numpy as np

embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", device="cpu")

transcript_embeddings = {}
for vid, text in transcripts.items():
    emb = embedder.encode(text, convert_to_tensor=True, show_progress_bar=False)
    transcript_embeddings[vid] = emb
print(f"Created embeddings for {len(transcript_embeddings)} transcripts")

import torch

def retrieve_top_k(query, k=3):
    """Return top-K most relevant transcripts for a given question."""
    query_emb = embedder.encode(query, convert_to_tensor=True)
    scores = []
    for vid, emb in transcript_embeddings.items():
        score = torch.nn.functional.cosine_similarity(query_emb, emb, dim=0)
        scores.append((vid, score.item()))
    top_k = sorted(scores, key=lambda x: x[1], reverse=True)[:k]
    return top_k

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_name = "Qwen/Qwen2.5-3B"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

import re

def generate_answer_from_transcripts(query, top_video_ids, transcripts):
    # Ensure IDs are strings, not tuples
    context_texts = [transcripts[vid_id[0]][:500] for vid_id in top_video_ids if vid_id[0] in transcripts]
    print()
    context = " ".join(context_texts)
    # Keep context short to avoid GPU overflow
    # context = context[:3000]

    prompt = f"Question: {query}\nContext: {context} Given the question with the answer options provide an answer with matching options based on the context and just output the Answer \nAnswer:"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=20,
            do_sample=False,
            temperature=0.5,
        )

    answer_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    match = re.search(r'Answer:\s*([A-D]\.\s*[^\n]*)', answer_text)
    return match.group(1) if match else answer_text

import evaluate
import numpy as np

# Load metrics
bleu = evaluate.load("bleu")
rouge = evaluate.load("rouge")

all_bleu_scores = []
all_rouge_scores = []
count_retrieved_correct = 0
num_que = 150

for i in range(num_que):
    sample = dataset["test"][i]
    query = sample["question"] + ", ".join(sample["options"])
    reference = next(opt for opt in sample["options"] if opt.startswith(sample["answer"]))

    # Retrieve top-k videos
    top_videos = retrieve_top_k(query, k=1)

    predicted = generate_answer_from_transcripts(query, top_videos, transcripts)

    # print(f"que: {sample['question']} \n ++++++ ans: {reference} \n +++++++ predicted: {predicted}")
    print(top_videos)
    print(f"Actual: {reference} \n Predicted: {predicted}")
    print("================================================")

    # Compute BLEU
    bleu_score = bleu.compute(predictions=[predicted], references=[[reference]])["bleu"]

    # Compute ROUGE-L
    rouge_score = rouge.compute(predictions=[predicted], references=[reference])["rougeL"]

    if top_videos[0][0] == sample["video_id"]:
      count_retrieved_correct += 1

    all_bleu_scores.append(bleu_score)
    all_rouge_scores.append(rouge_score)

# Compute average scores
mean_bleu = np.mean(all_bleu_scores)
mean_rouge = np.mean(all_rouge_scores)

print(f"\n\nAverage BLEU-4: {mean_bleu:.4f}")
print(f"Average ROUGE-L: {mean_rouge:.4f}")
print(f"Precision@1: {count_retrieved_correct/num_que}")

